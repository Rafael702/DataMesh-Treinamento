Por conta da velocidade e volume de dados que são produzidos todos os dias à
nossa volta, seja em redes sociais, no mundo financeiro ou nos serviços de
streaming, surge a demanda de uma área que seja capaz de lidar com esse cenário,
que é também conhecido como Big Data.

Nesse momento, passamos a ter a necessidade da Engenharia de Dados como área
responsável por cuidar desse fluxo de dados.

O termo Big Data, em português “grande volume de dados”, começou a aparecer
quando os métodos tradicionais para armazenamento começaram a não ser tão
eficientes nesse novo ambiente que exigia muito mais do que uma ferramenta de
armazenamento conseguia suportar.

De forma geral, o Big Data pode ser definido com 3 V’s principais:
Volume;
Variedade;
Velocidade.

1) Volume
Grande quantidade de dados para ser armazenada e processada, com escalas que
vão desde terabytes até mesmo zettabytes.

2) Variedade
A variedade de dados é um outro pilar do Big Data, pois, dentro do grande
volume de dados, temos diferentes tipos — desde dados estruturados,
semi-estruturados a não estruturados.

3) Velocidade
Essa grande quantidade de dados costuma ser gerada num curto espaço de tempo.
Um bom exemplo são as redes sociais, onde temos milhares de mensagens e
registros em bancos para serem atualizados.

A história da Engenharia de Dados começou com artigos da Google. O primeiro,
publicado em 2003, abordava o Google File System, um sistema de arquivos
distribuídos. Logo em seguida, em 2004, foi publicado outro artigo sobre
MapReduce, uma técnica de processamento de grandes volumes de dados.

Esses artigos inspiraram engenheiros do Yahoo a criarem, em 2006, o Hadoop,
que mostrou-se uma ferramenta muito útil para trabalhar com grandes volumes
de dados. A partir disso, surgiu a era da Engenharia de Dados com Big Data.
